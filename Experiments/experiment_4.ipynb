{
 "metadata": {
  "name": "",
  "signature": "sha256:3408cbdca621c6130ab60996dd6bd90353c8240112bb02c61b5310434ce24311"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Experiment 4"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this experiment is \n",
      "1. to visualize the difference in magnitude of the average values in the clusters. \n",
      "\n",
      "So far it seems that this is mostly what they are picking up.\n",
      "\n",
      "Here is how I want to do this\n",
      "\n",
      "1) Take the top 80% or some thing like that. Then compare the average value of these between clusters. And then take a look at them. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import os\n",
      "import copy\n",
      "import gzip\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import cPickle as cp\n",
      "import brainbox as bb\n",
      "import random  as rnd\n",
      "import nibabel as nib\n",
      "import multiprocessing as mp\n",
      "from scipy import stats as st\n",
      "from matplotlib import pyplot as plt\n",
      "import scipy.cluster.hierarchy as clh\n",
      "from mpl_toolkits.axes_grid1 import make_axes_locatable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Duplicate dropper\n",
      "def drop_duplicates(in_dict):\n",
      "    \"\"\"\n",
      "    Because python uses pointers and does not copy the variables\n",
      "    I can operate directly on the dictionary and change it in place\n",
      "    \"\"\"\n",
      "    cp_dict = copy.deepcopy(in_dict)\n",
      "    subs = cp_dict['sub_name']\n",
      "    dirs = cp_dict['dir']\n",
      "    path = cp_dict['path']\n",
      "    drop = list()\n",
      "    present = list()\n",
      "    sub_names = np.array([int64(re.search(r'(?<=\\d{2})\\d{5}', sub_id).group()) for sub_id in cp_dict['sub_name']])\n",
      "    for idx, sub in enumerate(sub_names):\n",
      "        if not sub in present:\n",
      "            present.append(sub)\n",
      "        else:\n",
      "            drop.append(idx)\n",
      "    print('Found {} items to drop'.format(len(drop)))\n",
      "    # Pop them in reverse order\n",
      "    for idx in drop[::-1]:\n",
      "        subs.pop(idx)\n",
      "        dirs.pop(idx)\n",
      "        path.pop(idx)\n",
      "    \n",
      "    return cp_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Paths\n",
      "metric = 'rmap_part'\n",
      "scale = 12\n",
      "in_path = '/data1/abide/Out/Remote/all_worked/out/sc12'\n",
      "out_path = '/data1/abide/Out/Remote/all_worked/out/maps/{}/scale_{}'.format(metric, scale)\n",
      "out_name = 'nondupl_linkage_scale{}_{}.gz'.format(scale, metric)\n",
      "out_file = os.path.join(out_path, out_name)\n",
      "\n",
      "file_dict = bb.fileOps.grab_files(in_path, '.nii.gz', metric)\n",
      "use_dict = drop_duplicates(file_dict)\n",
      "num_subs = len(use_dict['path'])\n",
      "\n",
      "if not os.path.isdir(out_path):\n",
      "    try:\n",
      "        os.makedirs(out_path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(out_path):\n",
      "            pass\n",
      "        else: raise\n",
      "\n",
      "out_file = os.path.join(out_path, out_name)\n",
      "if os.path.isfile(out_file):\n",
      "    print('{} does already exist, I will load things'.format(out_file))\n",
      "    f = gzip.open(out_file, 'rb')\n",
      "    in_data = cp.load(f)\n",
      "    data_subs = in_data[0]\n",
      "    results = in_data[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I will be pulling files from /data1/abide/Out/Remote/all_worked/out/sc12/rmap_part\n",
        "Found 49 items to drop\n",
        "/data1/abide/Out/Remote/all_worked/out/maps/rmap_part/scale_12/nondupl_linkage_scale12_rmap_part.gz does already exist, I will load things\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now generate clusters for the different networks\n",
      "tmp_i = nib.load(use_dict['path'][0])\n",
      "network = 10\n",
      "part_scale = 3\n",
      "distance, linkage = results[network]\n",
      "# Get the partition\n",
      "part = clh.fcluster(linkage, part_scale, criterion='maxclust')\n",
      "\n",
      "clust_list = list()\n",
      "\n",
      "for cluster in np.arange(1, part_scale + 1):\n",
      "    print('Computing stacks of cluster {} now'.format(cluster))\n",
      "    # Get the subjects in the cluster\n",
      "    clust_subs = [data_subs[x] for x in np.where(part==cluster)[0]]\n",
      "    clust_paths = [use_dict['path'][x] for x in np.where(part==cluster)[0]]\n",
      "    \n",
      "    for sidx, sub_path in enumerate(clust_paths):\n",
      "        img = nib.load(sub_path)\n",
      "        # Get the correct network\n",
      "        data = img.get_data()[..., network]\n",
      "        if sidx == 0: \n",
      "            clust_stack = data[..., None]\n",
      "        else:\n",
      "            clust_stack = np.concatenate((clust_stack, data[..., None]), axis=3)\n",
      "    mean = np.mean(clust_stack, axis=3)\n",
      "    std = np.std(clust_stack, axis=3)\n",
      "    \n",
      "    if cluster == 1:\n",
      "        clust_mean = mean[..., None]\n",
      "        clust_std = std[..., None]\n",
      "    else:\n",
      "        clust_mean = np.concatenate((clust_mean, mean[..., None]), axis=3)\n",
      "        clust_std = np.concatenate((clust_std, std[..., None]), axis=3)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Computing stacks of cluster 1 now\n",
        "Computing stacks of cluster 2 now"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Computing stacks of cluster 3 now"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "watch = np.reshape(clust_mean, (np.prod(clust_mean.shape[:3]), clust_mean.shape[3]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perc = np.percentile(watch, 70, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = watch > perc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(176384, 3)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "watch.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "(176384, 3)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q = np.zeros_like(watch)\n",
      "q[a] = watch[a]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(q, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([ 0.0669312 ,  0.15330423,  0.09417353], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "(176384, 3)"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}