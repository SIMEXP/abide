{
 "metadata": {
  "name": "",
  "signature": "sha256:19c50c93e1e4ca35fe1ea4dd42a7e85a27e30a24a47731308cc3522038f0556d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Experiment 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this experiment is to generate data derived clusters and have a look at the individual subjects inside of them\n",
      "1. cluster all subjects into clusters based on a given network metric and a given network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import os\n",
      "import copy\n",
      "import gzip\n",
      "import glob\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import cPickle as cp\n",
      "import brainbox as bb\n",
      "import random  as rnd\n",
      "import nibabel as nib\n",
      "import multiprocessing as mp\n",
      "from scipy import stats as st\n",
      "from matplotlib import pyplot as plt\n",
      "import scipy.cluster.hierarchy as clh\n",
      "from  __builtin__ import any as b_any\n",
      "from mpl_toolkits.axes_grid1 import make_axes_locatable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Paths\n",
      "metric = 'stability_maps'\n",
      "method = 'correlation'\n",
      "scale = 12\n",
      "in_path = '/data1/abide/Out/Remote/all_worked/out/sc12'\n",
      "out_path = '/data1/abide/Out/Remote/all_worked/out/maps/{}/{}/scale_{}'.format(metric, method, scale)\n",
      "out_name = 'nondupl_linkage_scale{}_{}_{}.gz'.format(scale, metric, method)\n",
      "out_file = os.path.join(out_path, out_name)\n",
      "if not os.path.isdir(out_path):\n",
      "    try:\n",
      "        os.makedirs(out_path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(out_path):\n",
      "            pass\n",
      "        else: raise\n",
      "\n",
      "ta_path = '/home/surchs/Project/abide/pheno/pheno_full.csv'\n",
      "ext = '.nii.gz'\n",
      "\n",
      "pheno = pd.read_csv(ta_path)\n",
      "targets = pheno['SUB_ID'].values\n",
      "file_dict = bb.fileOps.find_files(in_path, ext, targets, sub=metric)\n",
      "num_subs = len(file_dict['path'])\n",
      "data_subs = np.array([int(re.search(r'(?<=\\d{2})\\d{5}', sub_id).group()) for sub_id in file_dict['sub_name']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno_subs = pheno['SUB_ID']\n",
      "pheno_mask = pheno_subs.isin(data_subs)\n",
      "# Get the correct pheno data\n",
      "pheno_data = pheno[pheno_mask]\n",
      "# Save the pheno data\n",
      "pheno_data.to_csv(os.path.join(out_path, 'matched_pheno.csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno_data[100:101]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SITE_ID</th>\n",
        "      <th>SUB_ID</th>\n",
        "      <th>DX_GROUP</th>\n",
        "      <th>DSM_IV_TR</th>\n",
        "      <th>AGE_AT_SCAN</th>\n",
        "      <th>SEX</th>\n",
        "      <th>HANDEDNESS_CATEGORY</th>\n",
        "      <th>HANDEDNESS_SCORES</th>\n",
        "      <th>FIQ</th>\n",
        "      <th>VIQ</th>\n",
        "      <th>...</th>\n",
        "      <th>WISC_IV_BLK_DSN_SCALED</th>\n",
        "      <th>WISC_IV_PIC_CON_SCALED</th>\n",
        "      <th>WISC_IV_MATRIX_SCALED</th>\n",
        "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
        "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
        "      <th>WISC_IV_CODING_SCALED</th>\n",
        "      <th>WISC_IV_SYM_SCALED</th>\n",
        "      <th>EYE_STATUS_AT_SCAN</th>\n",
        "      <th>AGE_AT_MPRAGE</th>\n",
        "      <th>BMI</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>100</th>\n",
        "      <td> KKI</td>\n",
        "      <td> 50807</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 10.65</td>\n",
        "      <td> 1</td>\n",
        "      <td> Mixed</td>\n",
        "      <td> 41</td>\n",
        "      <td> 84</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "      <td> 11</td>\n",
        "      <td> 7</td>\n",
        "      <td> 8</td>\n",
        "      <td> 6</td>\n",
        "      <td> 5</td>\n",
        "      <td> 5</td>\n",
        "      <td> 7</td>\n",
        "      <td> 1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>1 rows \u00d7 74 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "    SITE_ID  SUB_ID  DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  SEX  \\\n",
        "100     KKI   50807         1          1        10.65    1   \n",
        "\n",
        "    HANDEDNESS_CATEGORY  HANDEDNESS_SCORES  FIQ  VIQ ...   \\\n",
        "100               Mixed                 41   84  NaN ...    \n",
        "\n",
        "     WISC_IV_BLK_DSN_SCALED WISC_IV_PIC_CON_SCALED WISC_IV_MATRIX_SCALED  \\\n",
        "100                      11                      7                     8   \n",
        "\n",
        "    WISC_IV_DIGIT_SPAN_SCALED  WISC_IV_LET_NUM_SCALED  WISC_IV_CODING_SCALED  \\\n",
        "100                         6                       5                      5   \n",
        "\n",
        "     WISC_IV_SYM_SCALED  EYE_STATUS_AT_SCAN  AGE_AT_MPRAGE  BMI  \n",
        "100                   7                   1            NaN  NaN  \n",
        "\n",
        "[1 rows x 74 columns]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dict['path'][100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "'/data1/abide/Out/Remote/all_worked/out/sc12/stability_maps/KKI_0050807_session_1_run1_stability_maps.nii.gz'"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_par(args):\n",
      "    \"\"\"\n",
      "    Wrapper function to run things in parallel\n",
      "    \"\"\"\n",
      "    use_dict, network, metric, method = args\n",
      "    data_dict = bb.fileOps.read_maps(use_dict, network=network, silence=True)\n",
      "    result = bb.dataOps.calc_link(data_dict, metric, method=method, network=0)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loop the data\n",
      "p_perc = 0.5\n",
      "p_count = int(np.floor(mp.cpu_count() * p_perc))\n",
      "\n",
      "out_file = os.path.join(out_path, out_name)\n",
      "if os.path.isfile(out_file):\n",
      "    print('{} does already exist, I will load things'.format(out_file))\n",
      "    f = gzip.open(out_file, 'rb')\n",
      "    in_data = cp.load(f)\n",
      "    data_subs = in_data[0]\n",
      "    results = in_data[1]\n",
      "    \n",
      "else:\n",
      "    # Remove the duplicates from the file dict\n",
      "    print('I will run things now')\n",
      "\n",
      "    results = list()\n",
      "    p = mp.Pool(p_count)\n",
      "    # Build the list of arguments\n",
      "    arg_list = list()\n",
      "    for network in np.arange(scale):\n",
      "        arg_list.append((file_dict, network, metric, method))\n",
      "    \n",
      "    results = p.map(run_par, arg_list)\n",
      "    # Write the results to disk for future use\n",
      "    data_subs = np.array([int64(re.search(r'(?<=\\d{2})\\d{5}', sub_id).group()) for sub_id in file_dict['sub_name']])\n",
      "    out = (data_subs, results)\n",
      "    outF = gzip.open(out_file, 'wb')\n",
      "    cp.dump(out, outF, protocol=2)\n",
      "    outF.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I will run things now\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "We are done\n",
        "We are done\n",
        "We are done\n",
        "We are done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We are done\n",
        "We are done\n",
        "We are done\n",
        "We are done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We are done\n",
        "We are done\n",
        "We are done\n",
        "We are done\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now generate clusters for the different networks\n",
      "tmp_i = nib.load(file_dict['path'][0])\n",
      "network = 10\n",
      "part_scale = 3\n",
      "distance, linkage = results[network]\n",
      "# Get the partition\n",
      "part = clh.fcluster(linkage, part_scale, criterion='maxclust')\n",
      "\n",
      "for cluster in np.arange(1, part_scale + 1):\n",
      "    print('Computing stacks of cluster {} now'.format(cluster))\n",
      "    # Get the subjects in the cluster\n",
      "    clust_subs = [data_subs[x] for x in np.where(part==cluster)[0]]\n",
      "    clust_paths = [file_dict['path'][x] for x in np.where(part==cluster)[0]]\n",
      "    \n",
      "    for sidx, sub_path in enumerate(clust_paths):\n",
      "        img = nib.load(sub_path)\n",
      "        # Get the correct network\n",
      "        data = img.get_data()[..., network]\n",
      "        if sidx == 0: \n",
      "            clust_stack = data[..., None]\n",
      "        else:\n",
      "            clust_stack = np.concatenate((clust_stack, data[..., None]), axis=3)\n",
      "    mean = np.mean(clust_stack, axis=3)\n",
      "    std = np.std(clust_stack, axis=3)\n",
      "    \n",
      "    if cluster == 1:\n",
      "        clust_mean = mean[..., None]\n",
      "        clust_std = std[..., None]\n",
      "    else:\n",
      "        clust_mean = np.concatenate((clust_mean, mean[..., None]), axis=3)\n",
      "        clust_std = np.concatenate((clust_std, std[..., None]), axis=3)\n",
      "    \n",
      "    stack_img = nib.Nifti1Image(clust_stack, tmp_i.get_affine(), tmp_i.get_header())\n",
      "    nib.save(stack_img, os.path.join(out_path, 'scale_{}_netw_{}_clust_{}_stack.nii.gz'.format(part_scale, network, cluster)))\n",
      "\n",
      "mean_img = nib.Nifti1Image(clust_mean, tmp_i.get_affine(), tmp_i.get_header())\n",
      "std_img = nib.Nifti1Image(clust_std, tmp_i.get_affine(), tmp_i.get_header())\n",
      "nib.save(mean_img, os.path.join(out_path, 'scale_{}_netw_{}_mean.nii.gz'.format(part_scale, network, cluster)))\n",
      "nib.save(std_img, os.path.join(out_path, 'scale_{}_netw_{}_std.nii.gz'.format(part_scale, network, cluster)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Computing stacks of cluster 1 now\n",
        "Computing stacks of cluster 2 now"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Computing stacks of cluster 3 now"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}